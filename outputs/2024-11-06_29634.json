{
    "ID": 29634,
    "title": "Will the US restrict access outside the US to some APIs to generative AI before 2025?\n",
    "prompt": "QUESTION:\nWill the US restrict access outside the US to some APIs to generative AI before 2025?\n\n\nTODAY'S DATE:\n2024-11-06\n\nRESOLUTION CRITERIA:\nThis question resolves as YES if, by Dec 31 2024, US law requires at least some powerful generative AI systems to restrict API access to only people in the US, and NO otherwise.\n\n\nADDITIONAL CRITERIA:\n* \"Powerful generative AI systems\" refers to AI that can solve a wide variety of tasks, such as GPT-4, and DALLE-2. Systems that translate, do text -> audio or audio -> text, summarize, search, etc. will not count as \"generative\".  If unclear, admins will determine \"powerful\" by whether the AI is known to frequently generate things that typically bother governments, such as Deep Fakes or instructions to build weapons.\n\n* \"Restrict\" here will be interpreted broadly. It could be by requiring AI owners to check IPs, like with DRM; it could be by requiring people to verify their identity to get API access tokens, like with KYC. Doesn't matter how easy it is to circumvent such restrictions such as via VPN.\n\n* \"Only people in the US\" will be interpreted broadly, it may include Americans who are abroad, or include non-permanent residents who are visiting, or require some verification only Americans can get like Social Security numbers.\n\nBACKGROUND:\nAs of May 2023, US law does not restrict API or browser access to any Large Language Models (LLMs), such as GPT-4 (ChatGPT) or Google Bard. As the capabilities of such systems grow, and users learn more how to extract certain types of knowledge (e.g. how to enrich uranium or create Deep Fakes), one way US policymakers might address risks would be to restrict usage to those that are verified to be in the US.\n\nA similar regime exists for Digital Rights Management for music & movies - access to music on Spotify or shows on Netflix or Prime Video may depend on your country of origin. (And people regularly use VPNs to pretend to be from some other place to access this content.) Copyrights and trade agreements more generally often have provisions for various countries, and some countries like China ban access to entire systems via firewalls.\n\nThis question asks about APIs, not browser or app usage, because APIs are the most flexible way to use large AI systems. (In April 2023, [Italy banned and then unbanned](https://www.theverge.com/2023/4/28/23702883/chatgpt-italy-ban-lifted-gpdp-data-protection-age-verification) ChatGPT's interface but not the API, which was decried as ineffectual.)\n\nADDITIONAL BACKGROUND:\nTo assess the likelihood of the US restricting access outside the US to some APIs for generative AI before 2025, here are some key points and background information:\n\n## Current Regulatory Landscape\nAs of May 2023, there are no US laws that restrict API or browser access to Large Language Models (LLMs) such as GPT-4 or Google Bard.\n\n## Executive Orders and Federal Policies\nPresident Biden issued an Executive Order in October 2023 focusing on the safe, secure, and trustworthy development and use of artificial intelligence. This order emphasizes the need for risk assessments, robust evaluations, and mitigation of risks associated with AI systems. However, it does not explicitly mandate restrictions on API access outside the US.\n\n## State-Level Regulations\nCalifornia has recently passed several AI-related bills that will come into effect in 2025 and 2026. These laws impose various obligations on developers and deployers of AI systems, including safety, transparency, and privacy measures. However, these regulations are state-specific and do not necessarily reflect federal policy or restrictions on international API access.\n\n## Predictive Forecasts\nOn Metaculus, a platform for predictive forecasting, the community prediction for the US restricting access outside the US to some APIs for generative AI before December 31, 2025, is around 23.5%.\n\n## Export Controls\nThere is a higher predicted likelihood (77%) of the US enacting export controls for some generative AI software before 2026, which might imply some form of restriction, but this does not specifically address API access restrictions outside the US.\n\n### Conclusion\nGiven the current information, there is no clear indication that the US will restrict access outside the US to some APIs for generative AI before 2025. The regulatory landscape is evolving, with significant activity at the state level and federal executive orders, but none of these measures have yet to impose such restrictions explicitly. Therefore, the answer to whether the US will restrict access outside the US to some APIs for generative AI before 2025 cannot be clearly determined as a yes or no based on the available information.\n\nRELEVANT SUBQUESTIONS:\n\nSUBQUESTION: Have any US lawmakers proposed legislation to restrict international access to generative AI APIs?\nANSWER: Yes, US lawmakers have proposed legislation to restrict international access to generative AI APIs.\n\nA new bill introduced by a group of lawmakers, known as the ENFORCE Act, aims to strengthen and simplify the Biden administration’s ability to impose export controls on artificial intelligence (AI) models. This legislation would grant the Commerce Department the authority to bar Americans from collaborating with foreign parties to develop AI systems that pose risks to US national security and would remove barriers to regulating the export of open-source AI models.\n\nAdditionally, the bill considers restricting the export of proprietary or closed-source AI models to specific nations and actors, which aligns with the goal of limiting international access to certain AI technologies.\n\n---\n\nSUBQUESTION: Have other countries implemented restrictions on international access to their generative AI technologies?\nANSWER: While the sources provide detailed information on AI regulations, especially within the EU, the US, and China, they do not explicitly state that other countries have implemented restrictions on international access to their generative AI technologies.\n\n- The EU's AI Act and its regulations are well-documented, but these are internal to the EU and do not address international access restrictions by other countries.\n- China's regulations are mentioned, but they focus on domestic regulation and do not specify international access restrictions.\n- The US approach is described as decentralized, but there is no mention of restrictions on international access to generative AI technologies.\n\nGiven the lack of specific information on this topic, the answer is:\n\n**UNCLEAR**\n\n---\n\nSUBQUESTION: Has the US government expressed concern about the misuse of generative AI technologies by foreign entities?\nANSWER: YES\n\nThe US government has indeed expressed concerns about the misuse of generative AI technologies by foreign entities. Here are some key points from the sources:\n\n- U.S. intelligence officials have warned about the growing threat from the accelerating pace of technological innovation, including the potential for AI models to be stolen and used by foreign actors, such as China, to enhance their hacking capabilities.\n- The annual threat assessment by the U.S. intelligence community highlighted that China, Russia, and Iran pose election security concerns, including the use of generative AI to spread disinformation and interfere in U.S. elections.\n- The Executive Order issued by President Biden emphasizes the need to mitigate risks associated with AI, including the potential for foreign persons to use AI models for malicious activities, and requires reporting on foreign transactions involving the training of large AI models.\n- The government is also focused on regulating AI to protect sensitive technologies from being used by countries of concern, including through export controls and reviews by the Committee on Foreign Investment in the United States (CFIUS).\n\n---\n\nSUBQUESTION: Is the US considering export controls on generative AI technologies before 2025?\nANSWER: YES, the US is considering export controls on generative AI technologies before 2025.\n\nSeveral sources indicate that the US has been actively working on tightening export controls on AI technologies, including generative AI, in recent months.\n\n- A bipartisan group of lawmakers introduced a bill in May 2024, known as the “Enhancing National Frameworks for Overseas Restriction of Critical Exports Act” or “ENFORCE Act,” which aims to control the export of AI systems, including those that could be used by foreign adversaries.\n- The US Department of Commerce has been given expanded authority to oversee and restrict the export of AI systems that could compromise US national security, with a focus on preventing the dissemination of advanced AI technologies to adversarial nations like China and Russia.\n- These measures are part of a broader effort to mitigate national security risks posed by the misuse of AI technologies, and they are being implemented or proposed well before 2025.\n\n---\n\nSUBQUESTION: Are there existing US laws that control the export of advanced technologies like encryption software?\nANSWER: Yes, there are existing US laws and regulations that control the export of advanced technologies, including those related to encryption software, although the specific sources provided do not directly mention encryption software.\n\nThe sources detail new export controls implemented by the U.S. Department of Commerce, Bureau of Industry and Security (BIS), which include regulations on the export of various advanced technologies such as quantum computing, semiconductor manufacturing, and additive manufacturing. These controls are part of the Export Administration Regulations (EAR) and involve the use of Export Control Classification Numbers (ECCNs) to classify and regulate the export of these technologies.\n\nWhile the sources do not explicitly mention encryption software, the broader framework of the EAR and the Export Administration Act of 1979 (and its subsequent amendments) do include controls on the export of encryption and other dual-use technologies. Historically, encryption software has been subject to export controls under the EAR, often classified under specific ECCNs.\n\nTherefore, based on the general context and the existing regulatory framework, it is clear that there are US laws and regulations that control the export of advanced technologies, including encryption software, even though the specific sources provided do not address encryption software directly.\n\n---\n\nSUBQUESTION: Has the US government previously restricted access to technologies or services based on user location?\nANSWER: Yes, the US government has previously restricted access to technologies or services based on various criteria, including user location and the handling of specific types of data.\n\nFor example, the Office 365 Government plans, as described in the service description, restrict access to customer content to screened Microsoft personnel and ensure that customer content is stored within the United States. This is specifically tailored for US federal, state, local, tribal, and territorial government entities, and other entities handling government-regulated data, indicating a restriction based on the location and type of data handled.\n\nAdditionally, federal regulations and policies, such as those outlined in the Federal Acquisition Regulation (FAR) Part 39, prohibit the use of certain telecommunications equipment or services from specific foreign companies, which can be seen as a form of restriction based on national security concerns and the origin of the technology.\n\nThese restrictions and compliance requirements effectively limit access to certain technologies or services based on the user's location and the nature of the data they handle.\n\n---\n\nSUBQUESTION: Have there been incidents where generative AI was used internationally in ways that threaten US national security?\nANSWER: YES.\n\nThere have been several indications and warnings about the use of generative AI in ways that could threaten US national security, both domestically and internationally.\n\n- Federal intelligence agencies have warned about the potential for generative AI to be used by foreign and domestic actors to create deepfake videos, disinformation campaigns, and other forms of election interference, which could disrupt the 2024 US election cycle.\n- The technology has been noted for its ability to produce highly targeted deepfake videos, disinformation campaigns, and cyberattacks at scale, posing significant threats to national security and trust in institutions.\n- There have been examples of AI-generated media being used to influence elections in other countries, such as an incident in a southern Indian state where an AI video encouraged voters to support a specific candidate on election day.\n- Additionally, the potential for generative AI to be used by adversaries to augment attack plotting, target election infrastructure, and create propaganda and false narratives has been highlighted.\n\n---\n\nSUBQUESTION: Is there significant public or political pressure in the US to limit international access to powerful generative AI systems?\nANSWER: There is indeed significant public and political interest in regulating and potentially limiting the access to powerful generative AI systems in the US, although the focus is more on domestic regulation and global standards rather than specifically on limiting international access.\n\n- The U.S. government has taken steps to regulate AI, including an executive order by President Joe Biden that mandates safety tests and the development of standards to ensure AI systems are safe, secure, and trustworthy. This order also addresses issues like content authentication and watermarking to protect against AI-enabled fraud and deception.\n- Congressional leaders are intensifying efforts to develop legislation directing agency regulation of AI technology, with a focus on security, accountability, and transparency. There have been discussions about creating a new federal agency dedicated to regulating AI and even an international AI regulatory body.\n- Public and policy discussions highlight concerns about national security, disinformation, and the potential misuse of generative AI, which suggests a growing pressure to implement regulatory measures that could indirectly influence international access to these technologies.\n\nWhile the primary emphasis is on regulating AI within the U.S. and setting global standards, these efforts could have implications for how these technologies are shared or accessed internationally. However, the specific focus on limiting international access is not the primary driver of these regulatory efforts.\n\n---\n\nSUBQUESTION: Are there legal mechanisms that would allow the US to restrict API access to generative AI based on geographical location?\nANSWER: Based on the available sources, there are indications that the US is moving towards regulating AI and could potentially implement mechanisms to restrict API access to generative AI based on geographical location, although it is not explicitly stated that such mechanisms are already in place.\n\n1. **Executive Order and Regulatory Frameworks**: The Biden administration has issued an executive order that mandates various safety and security measures for AI systems, including requirements for developers to share safety test results and develop standards to ensure AI systems are safe and secure. This suggests a framework where additional restrictions, including geographical access controls, could be implemented.\n\n2. **Proposed Legislation**: There are proposed bills, such as the California AI Transparency Act and other state-level legislation, that impose various regulations on AI systems. While these bills do not specifically mention geographical restrictions on API access, they indicate a trend towards more stringent regulation of AI, which could include such restrictions in the future.\n\n3. **Private Company Actions**: Companies like OpenAI have already taken steps to restrict API access to their AI models based on geographical location, specifically blocking access to users in China. This shows that the technical and administrative capabilities to implement such restrictions exist and are being used by private entities.\n\nGiven these points, while there is no explicit law currently in place that requires the restriction of API access to generative AI based on geographical location, the regulatory environment and private company actions suggest that such mechanisms could be legally implemented in the future.\n\n**UNCLEAR**\n\n---\n\nSUBQUESTION: Has the US government taken steps to regulate generative AI technologies domestically that could lead to international restrictions?\nANSWER: The US government has taken several steps towards regulating generative AI technologies domestically, although these steps are still in the developmental phase and have not yet resulted in comprehensive federal legislation.\n\n1. **Legislative Efforts**: Multiple bipartisan bills have been introduced in Congress to address various aspects of AI regulation, including generative AI. These bills focus on issues such as transparency, accountability, national security, and the protection of personal data.\n\n2. **Executive Actions**: President Biden issued an executive order in October 2023 to promote the safe, secure, and trustworthy development and use of artificial intelligence. This order includes action steps for oversight and regulation, such as standardized evaluations of AI systems and addressing security-related risks, though these are recommendations that would require congressional action to become enforceable law.\n\n3. **Regulatory Frameworks**: Various frameworks and guidelines have been proposed, including the SAFE Innovation Framework by Leader Schumer and the Blumenthal-Hawley approach, which aim to regulate AI with a focus on transparency, accountability, and risk-based regulation.\n\n4. **State-Level Regulations**: Several states have enacted or are considering comprehensive privacy legislation and AI-related bills, which can regulate AI technologies, including generative AI, at the state level.\n\n5. **Agency Involvement**: Agencies like the Federal Trade Commission (FTC) are actively involved in overseeing AI technologies, emphasizing the need for risk assessments and proposing new AI-related protections.\n\nWhile these steps indicate a strong interest in regulating generative AI domestically, they do not yet constitute comprehensive federal legislation. However, these efforts could lay the groundwork for more stringent regulations in the future, which could potentially influence international approaches to AI governance.\n\nTherefore, the answer is:\n**YES**, the US government has taken steps towards regulating generative AI technologies domestically, which could potentially lead to international restrictions or influence global AI governance.",
    "comment": "(a) **Time left until the outcome to the question is known:**\n\nApproximately **55 days** remain until December 31, 2024.\n\n---\n\n(b) **What the outcome would be if nothing changed:**\n\nIf nothing changed between now and the deadline, the outcome would be **NO**; there is currently no US law requiring powerful generative AI systems to restrict API access only to people in the US.\n\n---\n\n(c) **What I would forecast if there was only a quarter of the time left:**\n\nIf there were only about **14 days** left until the deadline, I would forecast a probability of around **1%**, considering the extremely limited time for any legislative action to occur.\n\n---\n\n(d) **What I would forecast if there was 4x the time left:**\n\nIf there were approximately **220 days** left (extending into mid-2025), I would assign a higher probability, perhaps around **10-15%**, allowing more time for potential legislative developments.\n\n---\n\n**Rationale:**\n\nGiven the current date of November 6, 2024, and the deadline of December 31, 2024, there are less than two months remaining for the US to enact a law requiring powerful generative AI systems to restrict API access only to people in the US.\n\nKey considerations:\n\n- **Legislative Timeline:** Enacting federal legislation typically requires substantial time due to the processes of drafting, committee reviews, debates, and approvals in both the House and Senate, followed by presidential signing. With only 55 days left, it is unlikely for new legislation of this nature to be introduced and passed.\n\n- **Current Legislative Activity:** While there have been legislative proposals and discussions around regulating AI, such as the ENFORCE Act aiming to strengthen export controls on AI technologies, none specifically mandate restricting API access based on user location within this timeframe.\n\n- **Executive Orders and Regulations:** The October 2023 Executive Order on AI focuses on safety, security, and trustworthiness but does not impose geographic API access restrictions.\n\n- **Export Controls vs. API Access Restrictions:** There is a higher likelihood of the US implementing export controls on AI technologies, which regulate the transfer of physical goods and software, but this is distinct from restricting access to APIs based on user location.\n\n- **Technical and Practical Challenges:** Implementing a legal requirement for API providers to restrict access based on geographic location would pose significant technical challenges and could face pushback from the tech industry due to concerns over innovation and global collaboration.\n\n- **International Relations:** Imposing such restrictions could have diplomatic implications and might conflict with existing trade agreements.\n\nGiven these factors, and the very limited time remaining in 2024, the probability of the US enacting such a law before the deadline is extremely low.\n\n---\n\n**Probability: 2%**",
    "probability": 2
}