{
    "ID": 29636,
    "title": "Before December 1, 2024, will laws be in place requiring that AI systems that emulate humans must reveal to people that they are AI?\n",
    "prompt": "QUESTION:\nBefore December 1, 2024, will laws be in place requiring that AI systems that emulate humans must reveal to people that they are AI?\n\n\nTODAY'S DATE:\n2024-11-06\n\nRESOLUTION CRITERIA:\nAs AI gets more powerful, it is likely that systems that can \"pass a Turing test\" and deceive people into believing that the AI is human will become available and controversial.\n\nFor example, the Google Duplex bot courted controversy with its extremely accurate mimicking of a human's voice, dialogue, and cadence. Public backlash prompted Google to [announce that the system would always first identify itself as a bot](https://www.bloomberg.com/news/articles/2018-05-10/google-grapples-with-horrifying-reaction-to-uncanny-ai-tech).\n\nBACKGROUND:\nCross-posted from [ai.metaculus](ai.metaculus.com). Originally sourced from [Science Bets](http://sciencebets.org/one_sided_predictions.html).\n\nADDITIONAL BACKGROUND:\nAs of the current date, there are several developments and proposals that pertain to the transparency and disclosure requirements for AI systems, particularly those that emulate humans or generate content that could be mistaken for human-created.\n\n## Federal Level\nThe Executive Order on the \"Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence\" issued by President Biden on October 30, 2023, does not specifically mandate that AI systems must reveal to people that they are AI. However, it does emphasize the protection of Americans' privacy and civil liberties, and it directs various federal agencies to develop and implement policies and regulations to ensure the safe and secure use of AI.\n\n## State Level\nSeveral state-level legislative proposals and enactments are relevant:\n- In California, the proposed \"California AI Transparency Act\" (SB 942) would require businesses providing generative AI systems with over 1 million monthly visitors to create an AI detection tool and include visible disclosures that the content was created by an AI system. This bill is still in the proposal stage as of January 2024.\n- Another California bill, AB2930, proposes requirements for entities using automated decision tools (ADTs), including disclosure to individuals that an ADT is being used. However, this does not specifically address the emulation of humans by AI systems.\n\n## Enacted Legislation\n- The enacted legislation in some states, such as HB1147 in an unspecified state, prohibits the distribution of undisclosed deepfakes in communications about candidates for elective office and requires disclosure when AI is used to interact with customers. However, this is more focused on deepfakes and electoral communications rather than general AI emulation.\n\nGiven the current state of these proposals and enactments, it is unclear whether laws specifically requiring AI systems that emulate humans to reveal their nature will be in place before December 1, 2024. While there are ongoing efforts and proposals aimed at increasing transparency and regulation around AI, the specific requirement for AI systems to disclose their artificial nature is not yet universally mandated at the federal or state levels.\n\nRELEVANT SUBQUESTIONS:\n\nSUBQUESTION: Are there currently any federal laws in the United States requiring AI systems that emulate humans to disclose that they are AI?\nANSWER: No, there are currently no federal laws in the United States that require AI systems that emulate humans to disclose that they are AI. While several bills have been introduced in Congress, such as the AI Labeling Act of 2023, none of these have been enacted into law yet. The regulation of AI is currently being addressed at the state level, with various states implementing their own disclosure requirements.\n\n---\n\nSUBQUESTION: Are major technology companies advocating for laws requiring AI systems to disclose that they are AI?\nANSWER: The sources indicate that while major technology companies are actively involved in lobbying for AI regulations, their advocacy does not uniformly support mandatory disclosure laws requiring AI systems to disclose that they are AI.\n\n- Major tech companies are lobbying for AI regulations, but they often advocate for more permissive or voluntary regulations rather than mandatory ones.\n- There is no clear evidence from the sources that these companies are specifically advocating for laws that require AI systems to disclose their use of AI. Instead, they are more focused on influencing the broader regulatory landscape and ensuring that regulations do not hinder their technological advancements.\n\nTherefore, the answer is:\n\n**UNCLEAR**\n\n---\n\nSUBQUESTION: Have any influential advocacy groups campaigned for legislation mandating disclosure by AI systems that emulate humans?\nANSWER: Yes, influential advocacy groups have campaigned for legislation mandating disclosure by AI systems that emulate humans.\n\nFor instance, various commenters and organizations mentioned in the sources have advocated for transparency and disclosure requirements for AI systems. The National Telecommunications and Information Administration (NTIA) report highlights comments from several groups, including the Centre for Information Policy Leadership, U.C. Berkeley Researchers, and the Greenlining Institute, which all emphasize the need for transparency and disclosure in AI systems to ensure accountability and prevent issues like algorithmic discrimination.\n\nAdditionally, the AI Labeling Act of 2023, which has been introduced in the Senate, includes provisions that require clear and conspicuous disclosures for AI-generated content, indicating support from legislative advocates for such transparency measures.\n\n---\n\nSUBQUESTION: Are there any active legislative proposals in the U.S. Congress that would mandate disclosure by AI systems emulating humans?\nANSWER: Yes, there are active legislative proposals in the U.S. Congress that would mandate disclosure by AI systems emulating humans.\n\n1. **AI Labeling Act of 2023**: This Senate bill requires disclosures for AI-generated content, including clear and conspicuous notices that the content is AI-generated, and metadata identifying the content as such.\n\n2. **QUIET Act and R U REAL Act**: These House bills aim to require disclosures when AI is used in robocalls and telemarketing. The QUIET Act would require robocallers using AI to mimic human voices to disclose this at the beginning of the calls, while the R U REAL Act would mandate disclosures on AI use in telemarketing.\n\n3. **AI Disclosure Act of 2023**: This House bill would require a disclaimer when any output is created by a generative AI model, stating that the output has been generated by artificial intelligence.\n\nThese proposals indicate ongoing legislative efforts to enforce disclosure requirements for AI systems that emulate human interactions.\n\n---\n\nSUBQUESTION: Have any notable incidents occurred where failure to disclose AI emulation of humans led to harm or public outcry?\nANSWER: Yes, there have been notable incidents and concerns related to the failure to disclose AI emulation of humans, which have led to harm or public outcry.\n\n1. **AI-Generated Images and Videos**: The use of AI to generate images or videos that depict intimate images of people without their consent has been a significant concern. This can lead to psychological distress for the victims and has prompted calls for clearer labeling and consent requirements.\n\n2. **Deep Fakes and Hallucinated Content**: The ability of AI to create deep fakes or other realistic but fabricated content has raised worries about deception and manipulation. This includes concerns about AI faking scientific work or other scholarly output, which can have serious consequences if not properly disclosed.\n\n3. **Simulation and Emotional Manipulation**: The human verisimilitude of AI simulations can provoke strong emotional responses, leading to manipulative interactions. There is a growing need for transparency about when individuals are interacting with AI simulations to avoid such manipulation.\n\nThese issues highlight the importance of disclosing when AI is being used to emulate humans to prevent harm and public outcry.\n\n---\n\nSUBQUESTION: Have any U.S. states enacted laws requiring AI systems that emulate humans to reveal to people that they are AI?\nANSWER: Yes, several U.S. states have enacted laws that require AI systems to reveal to people that they are interacting with AI, particularly when those systems emulate human-like interactions.\n\n- **Utah**: The Utah Artificial Intelligence Policy Act, effective May 1, 2024, requires businesses or individuals using generative AI to disclose to consumers that they are interacting with AI if the consumer asks.\n- **California**: The California AI Transparency Act, set to take effect on January 1, 2026, requires companies developing generative AI systems to provide AI detection tools and to include visible disclosures indicating that content has been AI-generated.\n- **Colorado**: Colorado's SB24-205, effective February 1, 2026, requires developers and deployers of high-risk AI systems to disclose to consumers when they are interacting with an AI system, especially if the system makes consequential decisions about them.\n\nThese laws aim to enhance transparency and consumer protection in the use of AI systems.\n\n---\n\nSUBQUESTION: Are there any active legislative proposals in U.S. state legislatures that would require AI systems emulating humans to disclose their artificial nature?\nANSWER: Yes, there are active legislative proposals and recently enacted laws in U.S. state legislatures that require AI systems emulating humans to disclose their artificial nature.\n\n## Utah\nThe Utah Artificial Intelligence Policy Act, which took effect on May 1, 2024, requires disclosure when consumers interact with generative AI systems. For non-regulated companies, disclosure is required if the consumer asks, while regulated companies must disclose this information prominently at the outset of the communication.\n\n## Colorado\nColorado Senate Bill 205 (SB205), set to become effective on February 1, 2026, includes provisions that require deployers of high-risk AI systems to notify consumers when they are interacting with an AI system, especially if the system makes consequential decisions about them.\n\n## California\nSeveral proposed bills in California also address this issue. For example, the California AI Transparency Act, introduced in January 2024, would require businesses to create an AI detection tool and include visible disclosures in AI-generated content to indicate that it was created by an AI system.\n\nThese laws and proposals highlight the growing trend of requiring transparency and disclosure when AI systems interact with consumers.\n\n---\n\nSUBQUESTION: Has any country enacted laws requiring AI systems that emulate humans to disclose that they are AI?\nANSWER: Yes, several laws and regulations in the United States, particularly at the state level, require disclosures when AI systems that emulate humans are used.\n\n- In Colorado, deployers of high-risk AI systems must notify consumers before a consequential decision is made that a high-risk AI system has been deployed, and they must disclose that the person is interacting with an AI system if asked or prompted.\n\n- The AI Labeling Act of 2023, although still a proposed bill at the federal level, requires clear and conspicuous disclosures for AI-generated content, including text, images, video, and audio, to identify that the content is AI-generated.\n\n- California's new generative AI law, signed into law on September 28, 2024, requires developers to disclose on their websites that the content was generated by an AI system, among other requirements.\n\n- Other states, such as Delaware and Illinois, also have laws or proposed bills that require transparency and disclosure when AI is used to interact with consumers or generate content.\n\n---\n\nSUBQUESTION: Is there historical precedent for similar laws being passed within a short time frame in response to technological advancements?\nANSWER: Yes, there is historical precedent for similar laws being passed within a relatively short time frame in response to technological advancements.\n\nFor example, the advent of the telegraph in the 19th century led to legal debates and changes. Courts had to determine whether telegraph companies should be treated as common carriers, which involved analyzing whether the old legal rules applied to this new technology. This process, though sometimes slow and contentious, demonstrates how legal systems responded to technological innovations.\n\nAnother example is the rapid legal responses to technological changes during the early Cold War era. The launch of Sputnik in 1957 created a policy window that led to the passage of the National Defense Education Act of 1958, which included various measures to expand STEM education and funding for science facilities. This legislation was prepared and consolidated quickly in response to the technological and strategic challenges posed by the Soviet Union.\n\nAdditionally, the evolution of commercial law in response to technological revolutions, such as the internet and fintech, has shown that legal systems can adapt, though often at a slower pace than the technological changes themselves. New laws and regulations have been developed to address the disruptions caused by these technologies, illustrating a pattern of legal response to technological advancements.\n\n---\n\nSUBQUESTION: Have there been recent significant public controversies over AI systems emulating humans without disclosure?\nANSWER: Yes, there have been recent significant public controversies and regulatory responses related to AI systems emulating humans without proper disclosure.\n\nSeveral states have enacted or proposed laws to address the transparency and disclosure of AI interactions, particularly when AI systems emulate human-like interactions without clear indication. For example:\n\n- Utah's Artificial Intelligence Policy Act requires companies to disclose when their AI systems are used to interact with consumers, especially in regulated occupations where disclosure is mandatory even without a consumer's prompt.\n- California's new AI laws, such as the Artificial Intelligence Training Data Transparency Act and SB 942, mandate disclosures about the use of generative AI and the data used to train these systems. These laws aim to ensure transparency and prevent deceptive use of AI-generated content.\n- Other states have also passed laws regulating the use of AI, particularly in contexts like deepfakes and political advertising, highlighting public concerns over the lack of transparency and potential deception.\n\nThese regulatory actions indicate ongoing public controversies and concerns about the lack of disclosure when AI systems emulate human interactions.",
    "comment": "(a) Time left until the outcome is known: **24 days**.\n\n(b) If nothing changed, the outcome would be: **Yes**, laws are in place requiring AI systems that emulate humans to reveal to people that they are AI.\n\n(c) Forecast if there was only a quarter of the time left (6 days): Probability remains high, as the laws are already enacted.\n\n(d) Forecast if there was 4x the time left (96 days): Probability remains high, with potential for additional laws to be enacted.\n\n---\n\n**Rationale:**\n\nAs of **November 6, 2024**, there are existing laws in the United States that require AI systems emulating humans to disclose their artificial nature to users. Notably:\n\n- **Utah's Artificial Intelligence Policy Act** became effective on **May 1, 2024**. This law mandates that businesses or individuals using generative AI must disclose to consumers that they are interacting with AI if the consumer asks. For regulated companies, the disclosure must be made prominently at the outset of the communication.\n\n- **Colorado's SB24-205**, while set to become effective on **February 1, 2026**, reflects the legislative trend toward requiring disclosure of AI interactions.\n\n- **California's AI Transparency Act (SB 942)**, although proposed to take effect on **January 1, 2026**, further indicates a growing legislative focus on AI transparency.\n\nGiven that **Utah's law** is already in effect and requires disclosure by AI systems that emulate humans, the condition of the question has been met. The question asks whether *laws will be in place* before **December 1, 2024**, and with Utah's legislation active, the answer is affirmative.\n\nThe short time frame remaining until the resolution date makes it highly unlikely that existing laws will be repealed or invalidated. Additionally, there is a possibility of more states enacting similar laws, but even without further legislative actions, the existence of current laws fulfills the question's criteria.\n\nConsidering these factors, the probability that the question resolves as **\"Yes\"** is extremely high.\n\n**Probability: 99%**",
    "probability": 99
}