{
    "ID": 30123,
    "ti        tle": "Will the US enact export controls for some generative AI software before 2025?\n",
    "prompt": "QUESTION:\nWill the US enact export controls for some generative AI software before 2025?\n\n\nTODAY'S DATE:\n2024-11-15\n\nRESOLUTION CRITERIA:\nThis question resolves as YES if, before January 1, 2025, the US imposes export controls on some generative AI software, and NO otherwise.\n\nADDITIONAL CRITERIA:\nThe export controls need not be specifically to China - anything under the standard export regime of the US would qualify.\n\nThe export controls must be specifically related to AI that can generate content. It is not sufficient if software produced by Microsoft or OpenAI cannot be exported to certain countries for other reasons - such as export bans on all software, or on all commercial products sold to certain countries.\n\nThese need to be actual export controls, as per the 2022 controls on semiconductors. Taxes or trade deals are not considered here.\n\nBACKGROUND:\nAs of May 2023, US law does not have export controls on the sale of software services that include powerful generative AI. As such, OpenAI, Anthropic, Google, and Microsoft can sell LLM-assisted document writing, image generation, video generation, etc. to enterprises worldwide (up to more general export controls not focused on AI.)\n\nIn Oct 2022, the [US implemented export controls](https://en.wikipedia.org/wiki/United_States_New_Export_Controls_on_Advanced_Computing_and_Semiconductors_to_China), that, roughly speaking, bans export of semiconductors that involve US in their manufacturing chain to China.\n\nAs the capabilities of generative AI systems grow, and as enterprise customers learn more how to extract certain types of knowledge (e.g. how to create Deep Fakes or create armies of online bots), one way US policymakers might address risks would be to apply exports control to software that are similar to the export controls for hardware used for training AI.\n\nADDITIONAL BACKGROUND:\nTo assess the likelihood of the US enacting export controls for generative AI software before 2025, here are some key points and background information:\n\n## Existing Export Controls and Regulations\nAs of May 2023, the US already has export controls in place for certain AI-related technologies, including restrictions on the sale of software services that include powerful generative AI. These controls are part of a broader effort to regulate technologies with potential national security implications[2][5].\n\n## Proposed Reporting Requirements\nIn September 2024, the Biden administration introduced a Notice of Proposed Rulemaking that includes mandatory reporting requirements for companies developing or planning to develop advanced AI models and computing clusters. This proposal is aimed at informing future regulatory decisions, including potential export controls, and is part of an executive order focused on the safe and secure development of AI[3][5].\n\n## Regulatory Posture and Intent\nThe US government has shown a clear intent to expand export controls on AI technologies. The proposed reporting requirements are seen as a precursor to more stringent regulations, including export controls on AI models based on their computing power. The Bureau of Industry and Security has already outlined reporting requirements for AI models utilizing more than \\(10^{26}\\) computational operations, which could be a basis for future restrictions[3][5].\n\n## Congressional and Administrative Actions\nThere are ongoing efforts at both the federal and state levels to regulate AI. Congressional committees have introduced several bills related to AI regulation, and there is bipartisan support for addressing AI policy priorities. The administration's actions, including the executive order and proposed reporting requirements, indicate a proactive approach to regulating AI[4][5].\n\n## Industry and International Considerations\nThe proposed export controls are controversial, with concerns raised by leading AI firms, civil society groups, and researchers about their practicality and potential impact on US leadership in AI innovation. However, key administration figures emphasize the security risks associated with AI as outweighing these costs[5].\n\nGiven these points:\n\n- The US has already implemented some export controls related to AI.\n- There are active proposals and rulemaking processes underway to expand these controls.\n- The regulatory environment is increasingly focused on AI, with a clear intent to regulate advanced AI models.\n\nIt is highly likely that the US will enact additional export controls for some generative AI software before 2025, given the current regulatory momentum and the administration's stated goals. However, the exact nature and scope of these controls are still subject to public comment and further regulatory development.\n\nRELEVANT SUBQUESTIONS:\n\nSUBQUESTION: Have other countries implemented export controls on generative AI software?\nANSWER: The information provided does not specifically address whether other countries, apart from the United States, have implemented export controls on generative AI software.\n\n- The sources discuss U.S. export controls and regulatory efforts in detail but do not mention similar controls in other countries[1][3][4].\n- While the sources do discuss AI regulations in other regions, such as the EU and China, these regulations focus more on the use, development, and safety of AI within those regions rather than export controls specifically[5].\n\nTherefore, the answer to whether other countries have implemented export controls on generative AI software is:\n\n**UNCLEAR**\n\n---\n\nSUBQUESTION: Has the US Congress introduced any legislation related to export controls on AI software?\nANSWER: Yes, the US Congress has introduced legislation related to export controls on AI software.\n\n- The \"Enhancing National Frameworks for Overseas Critical Exports Act\" (ENFORCE Act) is a bipartisan bill that would give the Department of Commerce’s Bureau of Industry and Security (BIS) the authority to use export controls on AI systems that threaten national security[1][2][5].\n- Another bill mentioned is the \"Remote Access Security Act,\" which would restrict remote access to advanced AI chips and expand the U.S. export control system to regulate remote access to AI technology[2][5].\n\nThese bills aim to address the gaps in current export control regulations and prevent AI technologies from being accessed by foreign adversaries.\n\n---\n\nSUBQUESTION: Is there strong opposition from major tech companies against export controls on generative AI software?\nANSWER: The sources do not indicate strong opposition from major tech companies against export controls on generative AI software. Here are some key points:\n\n- The discussions and regulations mentioned in the sources focus more on the governmental and regulatory aspects of export controls rather than the stance of major tech companies. For example, the US Department of Commerce and the Bureau of Industry and Security (BIS) are actively involved in imposing and updating these controls[2][4][5].\n- While there are mentions of tech companies and their interactions with these regulations, there is no clear indication of strong opposition. Instead, there are examples of companies finding workarounds or adapting to the controls, such as Nvidia developing less powerful chips to circumvent the export controls[4][5].\n- Some experts and analysts express concerns about the effectiveness and implications of these controls, but these are not necessarily representative of the views of major tech companies as a whole[4].\n\nTherefore, based on the provided sources, the answer is:\n\n**UNCLEAR**\n\n---\n\nSUBQUESTION: Has the US expanded export controls on AI hardware or computing technologies since 2022?\nANSWER: YES.\n\nSince 2022, the US has indeed expanded export controls on AI hardware and computing technologies. Here are some key points:\n\n- In 2022, the Biden administration imposed export controls to restrict China’s access to high-performance chips, aiming to prevent the development of AI systems that could enhance China’s military power[1].\n- In 2023 and 2024, the US further broadened these restrictions. The Bureau of Industry and Security (BIS) issued new rules and interim final rules that added export controls on semiconductor, quantum computing, and additive manufacturing items, all crucial for AI and high-performance computing[4][5].\n- The latest directives include specific restrictions on advanced AI chips, such as those produced by TSMC, to prevent their use by Chinese companies like Huawei, and extend controls to other countries, including those in the Persian Gulf[1][3].\n- The expansion also includes new license requirements and exceptions, such as the Data Center Validated End User Authorization, to ensure that sensitive technologies do not fall into the hands of foreign adversaries[2][5].\n\n---\n\nSUBQUESTION: Has the US government proposed any export controls specifically targeting generative AI software as of today?\nANSWER: As of today, the US government has indeed taken steps and proposed measures that include export controls targeting advanced AI systems, which can encompass generative AI software.\n\n- The Biden administration has been working on implementing export controls on AI models, including those with significant computing power, which could include generative AI. The Bureau of Industry and Security has published reporting requirements for AI models utilizing more than a certain threshold of operations, and there are discussions about restricting both open and closed-source AI models[2][3][4].\n\n- Specifically, the proposed legislation, such as the Enhancing National Frameworks for Overseas Restriction of Critical Exports Act (ENFORCE Act), aims to control the export of covered AI systems, which could include generative AI models, to prevent their exploitation by foreign adversaries[3][4].\n\n- Additionally, the executive order signed by President Joe Biden in October 2023 directed developers of powerful AI systems to share safety test results and other critical information with the US government, indicating a focus on regulating advanced AI technologies, including those related to generative AI[4].\n\nTherefore, the answer is:\n\n**YES**\n\n---\n\nSUBQUESTION: Has the US previously enacted export controls on software technologies due to national security concerns?\nANSWER: YES.\n\nThe US has indeed enacted export controls on software technologies due to national security concerns. Here are some key points from the sources:\n\n- The Export Administration Regulations (EAR) administered by the Bureau of Industry and Security (BIS) regulate the export, reexport, and transfer of items, including software and technologies, that have commercial uses but can also be used in conventional arms, weapons of mass destruction, terrorist activities, or human rights abuses[4][5].\n- Specific controls have been implemented on advanced technologies such as AI and semiconductor technology, which include software components. For example, the Biden administration enacted export controls restricting the sale of AI and semiconductor technology to China, which includes software used in these technologies[3].\n- The Commerce Control List (CCL) under the EAR includes categories that cover software and technology, such as Category 3 (Electronics Design Development and Production), Category 4 (Computers), and Category 5 Part 2 (Information Security), among others[5].\n\nThese measures demonstrate that the US has actively implemented export controls on software technologies to address national security concerns.\n\n---\n\nSUBQUESTION: Are influential US policymakers advocating for export controls on generative AI software?\nANSWER: YES\n\nInfluential US policymakers are indeed advocating for export controls on generative AI software and other AI systems. Here are some key points from the sources:\n\n- The House Foreign Affairs Committee has advanced the Enhancing National Frameworks for Overseas Restriction of Critical Exports (ENFORCE) Act, which aims to give the Department of Commerce’s Bureau of Industry and Security (BIS) the authority to control exports of covered AI systems, including those that could pose a national security threat[1][3][5].\n\n- Lawmakers, such as House Rep Michael McCaul, are emphasizing the need to regulate the export of AI systems to prevent them from being used by adversaries like China, highlighting concerns about national security and the potential for these technologies to be used in military or malign activities[1][5].\n\n- The proposed legislation includes measures to restrict remote access to advanced AI chips and to require licenses for the export of AI models that could be used in ways that erode U.S. national security or facilitate cyberattacks[3][4].\n\n---\n\nSUBQUESTION: Are there existing US regulations that could be extended to restrict exports of generative AI software?\nANSWER: Yes, there are existing US regulations that could be extended to restrict exports of generative AI software.\n\nThe Export Administration Regulations (EAR) already prohibit the export, reexport, and transfer of U.S.-origin commodities, software, and technology if there is knowledge that they will be used in the development, production, or use of certain prohibited items such as missiles, chemical or biological weapons, or nuclear weapons[1].\n\nSpecifically, EAR sections 744.2, 744.3, and 744.4, as well as Section 744.6, impose controls over activities of U.S. persons and the export of U.S.-origin technology and software, including AI models, if they could be used for prohibited end uses[1].\n\nAdditionally, recent directives and regulations, such as those targeting the export of advanced AI chips to China, demonstrate the ability and willingness of the US government to extend and modify export controls to include new technologies, including AI software[2][4].\n\nThe Export Control Reform Act of 2018 (ECRA) also gives the Department of Commerce the authority to promulgate new export control rules regarding AI technologies, further supporting the potential for extending existing regulations to restrict exports of generative AI software[5].\n\n---\n\nSUBQUESTION: Have there been any major incidents involving misuse of generative AI prompting regulatory discussions?\nANSWER: Yes, there have been significant incidents involving the misuse of generative AI that have prompted regulatory discussions and actions.\n\nSeveral sources highlight the various ways in which generative AI is being misused, such as creating deepfakes to mislead the public, generating sexually explicit fake images, and scamming vulnerable individuals. These misuses have led to calls for better governance and regulatory measures.\n\nFor example, a study by Google researchers analyzed approximately 200 incidents of generative AI misuse between January 2023 and March 2024, identifying common tactics such as manipulating human likeness, falsifying evidence, and using AI for scams and disinformation. This research aims to inform policymakers, trust and safety teams, and researchers on how to develop strategies to mitigate these harms[2][4][5].\n\nMicrosoft has also launched a White Paper titled \"Protecting the Public from Abusive AI-Generated Content,\" which emphasizes the need for a technological, legal, and partnership approach to tackle the misuse of generative AI. This initiative includes collaborations with law enforcement, election officials, and other stakeholders to address these issues[1].\n\nThese efforts and findings indicate that the misuse of generative AI is a significant concern that is driving regulatory discussions and actions.\n\n---\n\nSUBQUESTION: Are there significant national security concerns associated with the export of generative AI software?\nANSWER: Yes, there are significant national security concerns associated with the export of generative AI software. Here are some key points from the sources:\n\n## National Security Risks\n- Generative AI can be used to spread disinformation, conduct cyberattacks, and generate malicious code, which poses substantial risks to national security. For example, it can help rewrite code to make cyberattacks harder to attribute and generate code for more effective cyberattacks even by attackers with limited skills[4][5].\n\n## Unintended Harms and Misuse\n- The technology can be misused in unintended ways, such as in critical national infrastructure, public services, or private sector experimentation, which could lead to significant harm to national security[3].\n\n## Data and Information Risks\n- Generative AI systems can retain and misuse sensitive information entered into them, and when these systems are publicly and internationally accessible, they could provide benefits to adversaries[4].\n\n## Cybersecurity Implications\n- Generative AI can be exploited for fraud, malware creation, and investigation and reconnaissance support, enhancing the sophistication and efficiency of existing cyberattacks[5].\n\n## Global Impact\n- The export of such technology could amplify these risks globally, as it could be used by adversaries to inflict harm on a larger scale and with greater speed[3][4].\n\nThese concerns highlight the need for careful consideration and robust regulations when it comes to the export of generative AI software to ensure national security is not compromised.",
    "comment": "**(a) Time left until the outcome is known:**\n\nAs of today, November 15, 2024, there are 46 days remaining until January 1, 2025.\n\n---\n\n**(b) What the outcome would be if nothing changed:**\n\nIf nothing changed between now and January 1, 2025, the United States would not have enacted export controls specifically targeting generative AI software. Therefore, the outcome would be **NO**.\n\n---\n\n**(c) What I would forecast if there was only a quarter of the time left:**\n\nIf there were only about 11 days left until the deadline (a quarter of the remaining time), I would forecast a very low probability—around **5%**—that the U.S. would enact such export controls before January 1, 2025.\n\n---\n\n**(d) What I would forecast if there was 4x the time left:**\n\nIf there were approximately 184 days remaining (four times the current time left), extending the deadline to around mid-May 2025, I would increase my forecast to approximately **35%**, considering that additional time allows for regulatory processes to unfold.\n\n---\n\n**Rationale:**\n\n**Current State of Affairs:**\n\n- **Regulatory Momentum:** There has been significant activity in the U.S. regarding AI regulation. The Biden administration issued an executive order in October 2023 focusing on the safe and secure development of AI, including proposed reporting requirements for advanced AI models.\n\n- **Legislative Actions:** Congress has introduced legislation such as the ENFORCE Act and the Remote Access Restriction Act, which aim to give the Department of Commerce authority to control exports of certain AI systems, including generative AI.\n\n- **Administrative Processes:** The Bureau of Industry and Security (BIS) has published proposed rules and is considering export controls on AI technologies based on computing power thresholds.\n\n**Time Constraints:**\n\n- **Regulatory Timeline:** Enacting export controls involves a multi-step process, including drafting regulations, public comment periods (typically 30-60 days), revisions, and finalization. With only 46 days left in the year, and factoring in holidays like Thanksgiving and Christmas, the time available for these processes is extremely limited.\n\n- **Historical Precedent:** Past export control implementations have taken several months to over a year to move from proposal to enforcement.\n\n**Industry and Political Considerations:**\n\n- **Stakeholder Input:** Major tech companies and industry groups often provide significant feedback during public comment periods, which can delay or alter regulatory proposals.\n\n- **Political Climate:** While there is bipartisan interest in AI regulation, enacting export controls on software faces more complexity than hardware controls due to the pervasive and intangible nature of software.\n\n**Base Rates and Comparable Cases:**\n\n- **Export Controls on Software:** Historically, the U.S. has enacted export controls on software technologies due to national security concerns (e.g., encryption software in the 1990s). However, these controls took considerable time to implement and often faced legal and technical challenges.\n\n- **Likelihood of Rapid Action:** It is uncommon for significant export controls to be enacted within such a short timeframe without prior notice or emergency circumstances.\n\n**Potential Catalysts:**\n\n- **Major Incidents:** If a significant national security incident involving generative AI misuse were to occur imminently, it could accelerate regulatory actions. However, there's no current indication of such an event.\n\n- **International Developments:** Actions by other countries could influence U.S. policy, but there are no reports of other nations implementing export controls on generative AI software at this time.\n\n**Conclusion:**\n\nGiven the limited time remaining, the procedural requirements for enacting export controls, and the absence of immediate catalysts, the probability of the U.S. enacting export controls on some generative AI software before January 1, 2025, is low.\n\n---\n\n**Probability: 10%**",
    "probability": 10
}