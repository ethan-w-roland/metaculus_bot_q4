{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json, time\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_criteria_prompt = open(\"prompts/criteria.prompt\", \"r\").read()\n",
    "make_probabilites_prompt = open(\"prompts/make_probabilities.prompt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asknews_sdk import AskNewsSDK\n",
    "ask = AskNewsSDK(\n",
    "    client_id=os.getenv('ASKNEWS_ID'),\n",
    "    client_secret=os.getenv('ASKNEWS_SECRET')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_subquestion_prompt = open(\"prompts/ask_news/answer_sub.prompt\", \"r\").read()\n",
    "make_subquestion_prompt = open(\"prompts/ask_news/make_subquestion.prompt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sources(query, end_date:datetime):\n",
    "\n",
    "    response = ask.news.search_news(\n",
    "        query=query,\n",
    "        n_articles=20,\n",
    "        return_type=\"dicts\",\n",
    "        method=\"nl\",\n",
    "        end_timestamp=int(end_date.timestamp()),\n",
    "        historical=True\n",
    "    )\n",
    "\n",
    "    output = []\n",
    "    for x in response.as_dicts:\n",
    "        entry = {\n",
    "            \"title\": x.title,\n",
    "            \"summary\": x.summary,\n",
    "            \"pub_date\": x.pub_date.strftime(\"%Y-%m-%d\"),\n",
    "            \"source\": x.source_id\n",
    "        }\n",
    "        output.append(entry)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_subquestion(question:str, subquestion:str, date:datetime):\n",
    "\n",
    "    prompt = answer_subquestion_prompt.format(question=question, subquestion=subquestion)\n",
    "    sources = get_sources(question, date)\n",
    "\n",
    "    payload = \"\"\n",
    "    payload += f\"ORGINAL QUESTION: {question}\"\n",
    "    payload += f\"\\nSECONDARY QUESTION: {subquestion}\"\n",
    "    payload += \"\\n\\nRELEVANT WEB SOURCES:\"\n",
    "    for x in sources:\n",
    "        prompt += f\"\\n\\nTITLE: {x['title']}\\nPUB DATE: {x['pub_date']}\\nSOURCE: {x['source']}\\nSUMMARY: {x['summary']}\"\n",
    "    prompt += \"\\n\\nANSWER TO SECONDARY QUESTION:\\n\"\n",
    "    response = openai_client.chat.completions.create(\n",
    "        seed=42,\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_forecast(\n",
    "        question:str, \n",
    "        date:datetime=None,\n",
    "        background:str=None,\n",
    "        criteria:str=None, \n",
    "        fine_print:str=None):\n",
    "\n",
    "    if date is None:\n",
    "        date = datetime.now()\n",
    "\n",
    "    if criteria is None:\n",
    "        prompt = make_criteria_prompt.format(question=question)\n",
    "        response = openai_client.chat.completions.create(\n",
    "            seed=42,\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        criteria = response.choices[0].message.content\n",
    "\n",
    "    # get relevant sources\n",
    "    sources = get_sources(question, date)\n",
    "\n",
    "    # decompose question into subquestions\n",
    "    payload = \"\"\n",
    "    payload += f\"QUESTION:\\n{question}\"\n",
    "    payload += f\"\\n\\nTODAY'S DATE:\\n{date.strftime('%Y-%m-%d')}\"\n",
    "    payload += f\"\\n\\nRESOLUTION CRITERIA:\\n{criteria}\"\n",
    "    \n",
    "    if fine_print:\n",
    "        payload += f\"\\n\\nADDITIONAL CRITERIA:\\n{fine_print}\"\n",
    "\n",
    "    if background:\n",
    "        payload += f\"\\n\\nBACKGROUND:\\n{background}\"\n",
    "\n",
    "    payload += '\\n\\nRELEVANT WEB SOURCES:'\n",
    "    for x in sources:\n",
    "        payload += f\"\\n\\nTITLE: {x['title']}\\nPUB DATE: {x['pub_date']}\\nSOURCE: {x['source']}\\nSUMMARY: {x['summary']}\"\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        seed=42,\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": make_subquestions_prompt},\n",
    "            {\"role\": \"user\", \"content\": payload}],\n",
    "        response_format={ \"type\": \"json_object\" }\n",
    "    )\n",
    "\n",
    "    subquestions = response.choices[0].message.content\n",
    "    subquestions = json.loads(subquestions)\n",
    "    assert \"subquestions\" in subquestions\n",
    "    subquestions = subquestions[\"subquestions\"]\n",
    "\n",
    "    sub_values = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {}\n",
    "        for subquestion in subquestions:\n",
    "            future = executor.submit(answer_subquestion, question, subquestion, date)\n",
    "            futures[future] = subquestion\n",
    "        for future in as_completed(futures):\n",
    "            value = future.result()\n",
    "            subquestion = futures[future]\n",
    "            sub_values.append((subquestion, value))\n",
    "    \n",
    "    temp = []\n",
    "    for subquestion, value in sub_values:\n",
    "        if 'UNCLEAR' in value:\n",
    "            temp.append((subquestion, 'UNCLEAR'))\n",
    "        elif 'YES' in value:\n",
    "            temp.append((subquestion, 'YES'))\n",
    "        elif 'NO' in value:\n",
    "            temp.append((subquestion, 'NO'))\n",
    "    sub_values = temp\n",
    "\n",
    "    if sub_values:\n",
    "        payload += \"\\n\\nRELEVANT SUBQUESTIONS:\"\n",
    "        for subquestion, value in sub_values:\n",
    "            payload += f\"\\n\\nSUBQUESTION: {subquestion}\\nANSWER: {value}\"\n",
    "\n",
    "    print(payload)\n",
    "    print('-'*80)\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        seed=42,\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": make_probabilites_prompt},\n",
    "            {\"role\": \"user\", \"content\": payload}],\n",
    "    )\n",
    "\n",
    "    final_response = response.choices[0].message.content\n",
    "    print(final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_forecast(\n",
    "    question = \"Will the Real-time Sahm Rule Recession Indicator increase Year-over-Year for Nov 2024?\",\n",
    "    background = \"\"\"According to FRED: > Sahm Recession Indicator signals the start of a recession when the three-month moving average of the national unemployment rate (U3) rises by 0.50 percentage points or more relative to the minimum of the three-month averages from the previous 12 months. This indicator is based on \"real-time\" data, that is, the unemployment rate (and the recent history of unemployment rates) that were available in a given month. The BLS revises the unemployment rate each year at the beginning of January, when the December unemployment rate for the prior year is published. Revisions to the seasonal factors can affect estimates in recent years. Otherwise the unemployment rate does not revise.\"\"\",\n",
    "    criteria=\"This question will resolve based on reporting by the St. Louis Fed here:  https://fred.stlouisfed.org/series/SAHMREALTIME. The reported number for Nov 2024 must be greater than the reported for Nov 2023.\",\n",
    "    fine_print=\"The question will resolve according to the first value published for the period in question, later updates or revisions will be immaterial.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_forecast(\n",
    "    \"Will Prince Tom Iseghohi win the September 21, 2024 Edo state gubernatorial election in Nigeria?\",\n",
    "    date=datetime(2024, 9, 19),\n",
    "    criteria=\"This question resolves as Yes if Prince Tom Iseghohi is the next governor of Edo State in Nigeria, based on the results of the September 21, 2024 gubernatorial election according to the Independent National Electoral Commission of Nigeria or credible media reports on the election results.\",\n",
    "    fine_print=\"Although Nigeria typically counts its votes within a few days, if there is no declared winner before October 1, 2024, this question will be annulled.\",\n",
    "    background=\"\"\"Prince Tom Iseghohi is the Action Alliance's nominee for governor of Edo. The former Managing Director at Transnational Corp of Nigeria, Iseghohi was acquitted of money laundering charges in 2017.  Nigeria's Vanguard News in April 2024 named Iseghohi the frontrunner in the race, adding that \"is not only the fastest growing party in Nigeria but also the party to beat in the forthcoming September 21 governorship election in the state.\\\"\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "perplexity_client = OpenAI(\n",
    "    api_key=os.environ[\"PERPLEXITY_KEY\"], \n",
    "    base_url=\"https://api.perplexity.ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_background_prompt = open(\"prompts/perplexity/make_background.prompt\", \"r\").read()\n",
    "answer_subquestion_prompt = open(\"prompts/perplexity/answer_sub.prompt\", \"r\").read()\n",
    "make_subquestions_prompt = open(\"prompts/perplexity/make_sub.prompt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_background(question:str):\n",
    "\n",
    "    messages = [{'role':'system','content':make_background_prompt},\n",
    "                {'role':'user','content':question}]\n",
    "    response = perplexity_client.chat.completions.create(\n",
    "        seed=42,\n",
    "        model=\"llama-3.1-sonar-large-128k-online\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_subquestion(subquestion:str):\n",
    "\n",
    "    messages = [{'role':'system','content':answer_subquestion_prompt},\n",
    "                {'role':'user','content':subquestion}]\n",
    "    response = perplexity_client.chat.completions.create(\n",
    "        seed=42,\n",
    "        model=\"llama-3.1-sonar-large-128k-online\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def process_forecast_probabilty(forecast_text: str):\n",
    "    \"\"\"\n",
    "    Extract the forecast probability from the forecast text and clamp it between 1 and 99.\n",
    "    \"\"\"\n",
    "    matches = re.findall(r\"(\\d+)%\", forecast_text)\n",
    "    if matches:\n",
    "        # Return the last number found before a '%'\n",
    "        number = int(matches[-1])\n",
    "        number = min(99, max(1, number))  # clamp the number between 1 and 99\n",
    "        return number\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_forecast(\n",
    "        question:str, \n",
    "        date:datetime=None,\n",
    "        background:str=None,\n",
    "        criteria:str=None, \n",
    "        fine_print:str=None):\n",
    "    \n",
    "    if date is None:\n",
    "        date = datetime.now()\n",
    "\n",
    "    if criteria is None:\n",
    "        prompt = make_criteria_prompt.format(question=question)\n",
    "        response = openai_client.chat.completions.create(\n",
    "            seed=42,\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        criteria = response.choices[0].message.content\n",
    "    \n",
    "    # get perplexity background\n",
    "    extra_background = make_background(question)\n",
    "\n",
    "    # decompose question into subquestions\n",
    "    payload = \"\"\n",
    "    payload += f\"QUESTION:\\n{question}\"\n",
    "    payload += f\"\\n\\nTODAY'S DATE:\\n{date.strftime('%Y-%m-%d')}\"\n",
    "    payload += f\"\\n\\nRESOLUTION CRITERIA:\\n{criteria}\"\n",
    "    \n",
    "    if fine_print:\n",
    "        payload += f\"\\n\\nADDITIONAL CRITERIA:\\n{fine_print}\"\n",
    "\n",
    "    if background:\n",
    "        payload += f\"\\n\\nBACKGROUND:\\n{background}\"\n",
    "\n",
    "    payload += f'\\n\\nADDITIONAL BACKGROUND:\\n{extra_background}'\n",
    "\n",
    "    print(payload)\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        seed=42,\n",
    "        model=\"o1-preview\",\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": make_subquestions_prompt},\n",
    "            {\"role\": \"user\", \"content\": payload}]\n",
    "    )\n",
    "\n",
    "    subquestions = response.choices[0].message.content\n",
    "    subquestions = subquestions.split('\\n')\n",
    "    subquestions = [x.strip() for x in subquestions]\n",
    "    subquestions = [x for x in subquestions if x]\n",
    "\n",
    "    display(subquestions)\n",
    "\n",
    "    # make answers to each subquestion\n",
    "    sub_values = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {}\n",
    "        for subquestion in subquestions:\n",
    "            future = executor.submit(answer_subquestion, subquestion)\n",
    "            futures[future] = subquestion\n",
    "        for future in as_completed(futures):\n",
    "            value = future.result()\n",
    "            subquestion = futures[future]\n",
    "            sub_values.append((subquestion, value))\n",
    "\n",
    "    # make final probability\n",
    "    payload += \"\\n\\nRELEVANT SUBQUESTIONS:\"\n",
    "    for subquestion, value in sub_values:\n",
    "        payload += f\"\\n\\nSUBQUESTION: {subquestion}\\nANSWER: {value}\"\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        seed=42,\n",
    "        model=\"o1-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": make_probabilites_prompt},\n",
    "            {\"role\": \"user\", \"content\": payload}],\n",
    "    )\n",
    "\n",
    "    final_response = response.choices[0].message.content\n",
    "\n",
    "    # parse final_response to extract probability\n",
    "    probability = process_forecast_probabilty(final_response)\n",
    "\n",
    "    return (final_response, probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      "Will the Real-time Sahm Rule Recession Indicator increase Year-over-Year for Nov 2024?\n",
      "\n",
      "TODAY'S DATE:\n",
      "2024-10-16\n",
      "\n",
      "RESOLUTION CRITERIA:\n",
      "This question will resolve based on reporting by the St. Louis Fed here:  https://fred.stlouisfed.org/series/SAHMREALTIME. The reported number for Nov 2024 must be greater than the reported for Nov 2023.\n",
      "\n",
      "ADDITIONAL CRITERIA:\n",
      "The question will resolve according to the first value published for the period in question, later updates or revisions will be immaterial.\n",
      "\n",
      "BACKGROUND:\n",
      "According to FRED: > Sahm Recession Indicator signals the start of a recession when the three-month moving average of the national unemployment rate (U3) rises by 0.50 percentage points or more relative to the minimum of the three-month averages from the previous 12 months. This indicator is based on \"real-time\" data, that is, the unemployment rate (and the recent history of unemployment rates) that were available in a given month. The BLS revises the unemployment rate each year at the beginning of January, when the December unemployment rate for the prior year is published. Revisions to the seasonal factors can affect estimates in recent years. Otherwise the unemployment rate does not revise.\n",
      "\n",
      "ADDITIONAL BACKGROUND:\n",
      "To assess whether the Real-time Sahm Rule Recession Indicator will increase year-over-year for November 2024, here are some key points to consider:\n",
      "\n",
      "## Current State of the Indicator\n",
      "As of August 2024, the Real-time Sahm Rule Recession Indicator is at 0.57%, which is higher than the previous month (0.53%) and significantly higher than the same period last year (0.13%).\n",
      "\n",
      "## Historical Context and Accuracy\n",
      "The Sahm Rule has been highly accurate in signaling the onset of recessions since the 1950s, with only two false positive signals in its history. It relies on the three-month moving average of the national unemployment rate rising by 0.50 percentage points or more relative to its low over the previous 12 months.\n",
      "\n",
      "## Recent Trends\n",
      "The indicator has been increasing in recent months, reflecting a rise in the unemployment rate. For example, the unemployment rate rose from 4.1% in June 2024 to 4.3% in July 2024, triggering the Sahm Rule.\n",
      "\n",
      "## Economic Conditions\n",
      "While the triggering of the Sahm Rule is a concern, Claudia Sahm and other economists emphasize that other economic indicators, such as household income, consumer spending, and business investment, remain resilient. However, the labor market has shown signs of weakening, which could influence future readings of the indicator.\n",
      "\n",
      "## Year-over-Year Comparison\n",
      "To determine if the indicator will increase year-over-year for November 2024, we need to compare the expected November 2024 value with the November 2023 value. As of the latest data, the indicator has been increasing, but future values depend on the trajectory of the unemployment rate.\n",
      "\n",
      "Given the current trends and the recent increase in the unemployment rate, it is plausible that the indicator could remain elevated or continue to increase. However, predicting the exact value for November 2024 involves uncertainty due to potential changes in labor market conditions and other economic factors.\n",
      "\n",
      "### Key Points for Superforecasters:\n",
      "- **Base Rate**: The Sahm Rule has a strong historical accuracy in signaling recessions.\n",
      "- **Current Trends**: The indicator has been increasing, reflecting rising unemployment rates.\n",
      "- **Economic Conditions**: Mixed signals with some resilience in household income and consumer spending but weakening labor market.\n",
      "- **Time to Resolution**: The next release of the indicator is in October 2024, and the November value will depend on the subsequent unemployment data.\n",
      "- **Reference Class**: Historical performance of the Sahm Rule and current economic conditions.\n",
      "\n",
      "Without specific unemployment rate projections for November 2024, it is not possible to definitively answer whether the Real-time Sahm Rule Recession Indicator will increase year-over-year. However, the current upward trend and the recent triggering of the rule suggest a heightened likelihood of continued elevation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Did the Real-time Sahm Rule Recession Indicator for November 2023 exceed 0.10%?',\n",
       " 'Was the national unemployment rate in November 2024 higher than in November 2023?',\n",
       " 'Has the three-month moving average of the national unemployment rate for November 2024 increased compared to November 2023?',\n",
       " 'Did the national unemployment rate rise by at least 0.50 percentage points in the three months leading up to November 2024 compared to the previous 12-month minimum?',\n",
       " 'Have there been any significant revisions to the unemployment rate data for November 2024 after its initial release?',\n",
       " 'Has the unemployment rate consistently increased from August 2024 to November 2024?',\n",
       " 'Have economic indicators such as household income or consumer spending declined in the months leading up to November 2024?',\n",
       " 'Has the labor market shown signs of weakening in the months leading up to November 2024?',\n",
       " 'Were there any major economic policy changes affecting unemployment between November 2023 and November 2024?',\n",
       " 'Is the Real-time Sahm Rule Recession Indicator for October 2024 higher than it was in October 2023?']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**(a) The time left until the outcome to the question is known.**\n",
      "- **Approximately 1.5 weeks** remain until the Real-time Sahm Rule Recession Indicator for November 2024 is published.\n",
      "\n",
      "**(b) What the outcome would be if nothing changed.**\n",
      "- **If nothing changes**, the Real-time Sahm Rule Recession Indicator would **remain at or slightly above its current level of 0.57%**, maintaining an increase year-over-year compared to November 2023.\n",
      "\n",
      "**(c) What you would forecast if there was only a quarter of the time left.**\n",
      "- **With only a quarter of the time left (approximately 3-4 weeks)**, I would forecast a **high probability (around 85%)** that the indicator will continue its upward trend, given the current weakening labor market conditions and the existing upward trend in the indicator.\n",
      "\n",
      "**(d) What you would forecast if there was 4x the time left.**\n",
      "- **With 4 times the time left (approximately 6 weeks)**, there is more room for economic conditions to change. Factors such as potential policy interventions, unexpected economic stimuli, or shifts in labor market dynamics could influence the indicator. In this scenario, I would forecast a **moderate probability (around 70%)** that the indicator will increase year-over-year, acknowledging the increased uncertainty over a longer timeframe.\n",
      "\n",
      "**Rationale:**\n",
      "The Real-time Sahm Rule Recession Indicator has shown a significant increase from 0.13% in November 2023 to 0.57% in August 2024, indicating a deteriorating labor market. Recent trends reinforce this upward trajectory, with the unemployment rate rising and the labor market showing signs of weakening. Although household income and consumer spending remain resilient, the persistent increase in unemployment rates and the triggering of the Sahm Rule suggest that the indicator is likely to continue its upward trend.\n",
      "\n",
      "Given that the time until resolution is relatively short (approximately 1.5 weeks), and the current data already shows an elevated indicator, the probability remains high that the indicator will increase year-over-year for November 2024. However, slight economic adjustments or policy measures in the coming weeks could have minor impacts, but the overall trend supports a continued increase.\n",
      "\n",
      "**Probability: 80%**\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "resp, prob = make_forecast(\n",
    "    question = \"Will the Real-time Sahm Rule Recession Indicator increase Year-over-Year for Nov 2024?\",\n",
    "    background = \"\"\"According to FRED: > Sahm Recession Indicator signals the start of a recession when the three-month moving average of the national unemployment rate (U3) rises by 0.50 percentage points or more relative to the minimum of the three-month averages from the previous 12 months. This indicator is based on \"real-time\" data, that is, the unemployment rate (and the recent history of unemployment rates) that were available in a given month. The BLS revises the unemployment rate each year at the beginning of January, when the December unemployment rate for the prior year is published. Revisions to the seasonal factors can affect estimates in recent years. Otherwise the unemployment rate does not revise.\"\"\",\n",
    "    criteria=\"This question will resolve based on reporting by the St. Louis Fed here:  https://fred.stlouisfed.org/series/SAHMREALTIME. The reported number for Nov 2024 must be greater than the reported for Nov 2023.\",\n",
    "    fine_print=\"The question will resolve according to the first value published for the period in question, later updates or revisions will be immaterial.\"\n",
    ")\n",
    "\n",
    "print(resp)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
